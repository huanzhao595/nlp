{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7858e3aa-c92a-44e3-809d-e5f500a21d68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c0ad6c-8138-4627-963e-397cc51c718a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_latent = 100\n",
    "\n",
    "def set_seed(seed=2021):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda54e9f-7fdb-4018-b382-8524a62398da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 清理 GPU 缓存\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f78502-0b3c-4b97-84bd-18d5f8e1f978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load data and create a label\n",
    "loaded_mem_tensor = torch.load('mia/output_member_100_seqs.pt')\n",
    "print(loaded_mem_tensor.shape)\n",
    "mem_y = [1] * len(loaded_mem_tensor)  # 1 represent member class\n",
    "\n",
    "loaded_nonmem_tensor = torch.load('mia/output_nonmember_100_seqs.pt')\n",
    "print(loaded_nonmem_tensor.shape)\n",
    "nonmem_y = [0] * len(loaded_nonmem_tensor)  # 0 represent non-member class\n",
    "# loaded__mem_tensor.shape, loaded__nonmem_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3f46c9-daaf-49db-81aa-05cb389a63c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(loaded_mem_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "99cfbbcd-7f15-4b1e-b6b3-528c958259a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded__mem_tensor), type(loaded_nonmem_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "96aa2f18-2fc5-4abd-887d-96b6e8f9a9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0')\n",
    "# loaded__mem_tensor = loaded__mem_tensor.to(device)\n",
    "# loaded__nonmem_tensor = loaded__nonmem_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bd3e66fb-660d-43c3-8e9d-7137fb2cb09e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# print(loaded__mem_tensor.device)  # 输出 mem 数据所在设备\n",
    "# print(loaded__nonmem_tensor.device)  # 输出 nonmem 数据所在设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "12274dfa-9b32-40d4-b3d8-54461f069414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 52740]), torch.Size([10, 52740]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cpu')  # 使用 CPU\n",
    "# loaded__mem_tensor = loaded__mem_tensor.to(device)\n",
    "# loaded__nonmem_tensor = loaded__nonmem_tensor.to(device)\n",
    "# loaded__mem_tensor.shape, loaded__nonmem_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60556376-16b3-479b-a6bc-fc7d0806417e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the data for training\n",
    "data = torch.cat((loaded_mem_tensor, loaded_nonmem_tensor), dim=0)\n",
    "labels = torch.tensor(mem_y + nonmem_y)\n",
    "len(data), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5670bf-c8e5-4741-9338-e1ee4acd0cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d3bbdc2-1a9e-4409-a01e-8c0e1f28403b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing\n",
    "\n",
    "# 转换为 NumPy 格式以便划分\n",
    "data_np = data.cpu().detach().numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_np, labels_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13f3743-2fec-444f-8286-ffd747a77110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a66c383-8f11-47ca-9b9a-55b7d322529c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0cb064c-2d36-4a84-b775-54c291d60a05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b78f92a-80c3-4518-a523-1301dfd0a005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b435ecb-2fd0-4095-847b-f14e0db45c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=1000, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP(input_size)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mlp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0913166a-5178-490b-ac8c-c9729163910b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train Loss: 0.693149, Train Acc: 0.506250\n",
      "epoch: 1, Train Loss: 0.693064, Train Acc: 0.506250\n",
      "epoch: 2, Train Loss: 0.693087, Train Acc: 0.506250\n",
      "epoch: 3, Train Loss: 0.693106, Train Acc: 0.506250\n",
      "epoch: 4, Train Loss: 0.693072, Train Acc: 0.506250\n",
      "epoch: 5, Train Loss: 0.693121, Train Acc: 0.506250\n",
      "epoch: 6, Train Loss: 0.693093, Train Acc: 0.506250\n",
      "epoch: 7, Train Loss: 0.693114, Train Acc: 0.506250\n",
      "epoch: 8, Train Loss: 0.693105, Train Acc: 0.506250\n",
      "epoch: 9, Train Loss: 0.693122, Train Acc: 0.506250\n",
      "epoch: 10, Train Loss: 0.693099, Train Acc: 0.506250\n",
      "epoch: 11, Train Loss: 0.693069, Train Acc: 0.506250\n",
      "epoch: 12, Train Loss: 0.693133, Train Acc: 0.506250\n",
      "epoch: 13, Train Loss: 0.693143, Train Acc: 0.506250\n",
      "epoch: 14, Train Loss: 0.693077, Train Acc: 0.506250\n",
      "epoch: 15, Train Loss: 0.693081, Train Acc: 0.506250\n",
      "epoch: 16, Train Loss: 0.693118, Train Acc: 0.506250\n",
      "epoch: 17, Train Loss: 0.693072, Train Acc: 0.506250\n",
      "epoch: 18, Train Loss: 0.693092, Train Acc: 0.506250\n",
      "epoch: 19, Train Loss: 0.693100, Train Acc: 0.506250\n",
      "epoch: 20, Train Loss: 0.693067, Train Acc: 0.506250\n",
      "epoch: 21, Train Loss: 0.693092, Train Acc: 0.506250\n",
      "epoch: 22, Train Loss: 0.693162, Train Acc: 0.506250\n",
      "epoch: 23, Train Loss: 0.693067, Train Acc: 0.506250\n",
      "epoch: 24, Train Loss: 0.693103, Train Acc: 0.506250\n",
      "epoch: 25, Train Loss: 0.693080, Train Acc: 0.506250\n",
      "epoch: 26, Train Loss: 0.693151, Train Acc: 0.506250\n",
      "epoch: 27, Train Loss: 0.693100, Train Acc: 0.506250\n",
      "epoch: 28, Train Loss: 0.693110, Train Acc: 0.506250\n",
      "epoch: 29, Train Loss: 0.693092, Train Acc: 0.506250\n",
      "epoch: 30, Train Loss: 0.693093, Train Acc: 0.506250\n",
      "epoch: 31, Train Loss: 0.693111, Train Acc: 0.506250\n",
      "epoch: 32, Train Loss: 0.693075, Train Acc: 0.506250\n",
      "epoch: 33, Train Loss: 0.693091, Train Acc: 0.506250\n",
      "epoch: 34, Train Loss: 0.693084, Train Acc: 0.506250\n",
      "epoch: 35, Train Loss: 0.693121, Train Acc: 0.506250\n",
      "epoch: 36, Train Loss: 0.693079, Train Acc: 0.506250\n",
      "epoch: 37, Train Loss: 0.693075, Train Acc: 0.506250\n",
      "epoch: 38, Train Loss: 0.693122, Train Acc: 0.506250\n",
      "epoch: 39, Train Loss: 0.693096, Train Acc: 0.506250\n",
      "epoch: 40, Train Loss: 0.693128, Train Acc: 0.506250\n",
      "epoch: 41, Train Loss: 0.693143, Train Acc: 0.506250\n",
      "epoch: 42, Train Loss: 0.693076, Train Acc: 0.506250\n",
      "epoch: 43, Train Loss: 0.693100, Train Acc: 0.506250\n",
      "epoch: 44, Train Loss: 0.693083, Train Acc: 0.506250\n",
      "epoch: 45, Train Loss: 0.693071, Train Acc: 0.506250\n",
      "epoch: 46, Train Loss: 0.693133, Train Acc: 0.506250\n",
      "epoch: 47, Train Loss: 0.693094, Train Acc: 0.506250\n",
      "epoch: 48, Train Loss: 0.693099, Train Acc: 0.506250\n",
      "epoch: 49, Train Loss: 0.693103, Train Acc: 0.506250\n",
      "TruePositive: 0\n",
      "FalsePositive: 0\n",
      "TrueNegative: 19\n",
      "FalseNegative 21\n",
      "accuarcy: \n",
      "9.5\n",
      "recall: \n",
      "0.0\n",
      "AUC: \n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=0.01, momentum=0.7)\n",
    "\n",
    "# accuarcy\n",
    "def AccuarcyCompute(pred, label):\n",
    "    pred = pred.cpu().data.numpy()\n",
    "    label = label.cpu().data.numpy()\n",
    "    #    print(pred.shape(),label.shape())\n",
    "    test_np = (np.argmax(pred, 1) == label)\n",
    "    test_np = np.float32(test_np)\n",
    "    return np.mean(test_np)\n",
    "\n",
    "\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "for x in range(50):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # _, pred = outputs.max(1)\n",
    "        # print(outputs.shape)\n",
    "        # _, predicted = torch.max(outputs, 1)\n",
    "        # print(predicted.shape)\n",
    "        # if(predicted == labels.cpu().numpy()[0]): # int(pred)\n",
    "            # train_acc += 1\n",
    "        train_acc += AccuarcyCompute(outputs, labels)\n",
    "\n",
    "        # print(x, \":\", AccuarcyCompute(outputs, labels))\n",
    "    losses.append(train_loss / len(train_loader))\n",
    "    acces.append(train_acc / len(train_loader))\n",
    "    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}'.format(x, train_loss / len(train_loader),\n",
    "                                                                    train_acc / len(train_loader)))\n",
    "\n",
    "acc_ans = 0\n",
    "TruePositive = 0\n",
    "FalsePositive = 0\n",
    "TrueNegative = 0\n",
    "FalseNegative = 0\n",
    "for inputs, labels in test_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = mlp(inputs)\n",
    "    # print(outputs)\n",
    "    # _, pred = outputs.max(1)\n",
    "    # if int(pred) == labels.numpy()[0]:\n",
    "    #     acc_ans += 1\n",
    "    #     if int(pred) == 1:\n",
    "    #         TruePositive = TruePositive + 1\n",
    "    #     else:\n",
    "    #         TrueNegative = TrueNegative + 1\n",
    "    # else:\n",
    "    #     if int(pred) == 1:\n",
    "    #         FalsePositive = FalsePositive + 1\n",
    "    #     else:\n",
    "    #         FalseNegative = FalseNegative + 1\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    for pred, label in zip(predicted, labels):\n",
    "            if pred == label:\n",
    "                acc_ans += 1\n",
    "                if pred == 1:\n",
    "                    TruePositive += 1\n",
    "                else:\n",
    "                    TrueNegative += 1\n",
    "            else:\n",
    "                if pred == 1:\n",
    "                    FalsePositive += 1\n",
    "                else:\n",
    "                    FalseNegative += 1\n",
    "\n",
    "print('TruePositive:', TruePositive)\n",
    "print('FalsePositive:', FalsePositive)\n",
    "print('TrueNegative:', TrueNegative)\n",
    "print('FalseNegative', FalseNegative)\n",
    "print(\"accuarcy: \")\n",
    "print((acc_ans / len(test_loader)))\n",
    "\n",
    "if (TruePositive + FalsePositive) != 0:\n",
    "    print(\"precsion: \")\n",
    "    print((TruePositive / (TruePositive + FalsePositive)))\n",
    "if (TruePositive + FalseNegative) != 0:\n",
    "    print(\"recall: \")\n",
    "    print((TruePositive / (TruePositive + FalseNegative)))\n",
    "\n",
    "if (TruePositive + FalseNegative) !=0:\n",
    "    TPRate = TruePositive / (TruePositive + FalseNegative)\n",
    "if (FalsePositive + TrueNegative) !=0:\n",
    "    FPRate = FalsePositive / (FalsePositive + TrueNegative)\n",
    "area = 0.5 * TPRate * FPRate + 0.5 * (TPRate + 1) * (1 - FPRate)\n",
    "print(\"AUC: \")\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdc8ef-4fc0-4ea2-94da-f39e6d23d0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486de46-595a-4ac0-a3b9-7f9063f46c52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
